{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smart_glove.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NithinPrd/Glovify/blob/master/smart_glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHhtZ-1LTrXD",
        "colab_type": "text"
      },
      "source": [
        "Import all required packages. This includes:\n",
        "\n",
        "\n",
        "*   pandas for dataframe\n",
        "*   matplotlib for basic plotting\n",
        "*   scikit-learn for random forest algorithm\n",
        "*   seaborn for visualization\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL2cvBNNTeee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mp\n",
        "import seaborn as sb\n",
        "\n",
        "# Importing the required packages\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYtsJ7rfT3Zw",
        "colab_type": "text"
      },
      "source": [
        "# **Allow colab to access Google Drive.**\n",
        "\n",
        "Mounting Drive with content specification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kepgJuG7-CB",
        "colab_type": "code",
        "outputId": "1561c664-40fb-4438-d3c2-fa186f20a85e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr1hT0KiUOHW",
        "colab_type": "text"
      },
      "source": [
        "# **Import datasets**\n",
        "\n",
        "The following functions are performed in following block:\n",
        "\n",
        "\n",
        "1.   Initialization of joint dataframe\n",
        "2.   Importing each .csv from Google Drive and storing it in a dataframe\n",
        "3.   Filter the columns of the dataframe by selecting only required columns\n",
        "4.   Insert the corresponding character into the dataframe in a separate column\n",
        "5.   In blank fields, insert the median value of the corresponding columns. This is done individually for each imported dataset.\n",
        "6.   Values in the final dataframe are filtered in order to obtain the values within a particular range.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgZXI3JZr6Pe",
        "colab_type": "code",
        "outputId": "cb11e5a1-43d4-4fd3-e88c-2a416713878f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "#datapath = \"/content/drive/My Drive/Smart Glove Data/alphabets with flex only/csvfile1.csv\"   # Replace with required file name\n",
        "from string import ascii_uppercase\n",
        "\n",
        "\n",
        "finaldata = pd.DataFrame(columns=(['index','middle','ring','little','thumb']))\n",
        "\n",
        "j=0\n",
        "\n",
        "#For datasets having 1,000 values - Characters\n",
        "for i in ascii_uppercase:\n",
        "  datapath = \"/content/drive/My Drive/Smart Glove Data/alphabets with flex only/Alphabet\"+i+\".csv\"\n",
        "  data = pd.read_csv(datapath)\n",
        "  for k in data.columns:     #data.columns[w:] if you have w column of line description \n",
        "    data[k] = data[k].fillna(data[k].median())\n",
        "  data = data.filter(['index','middle','ring','little','thumb'])\n",
        "  data.insert(5,'Character',j)\n",
        "  j=j+1\n",
        "  finaldata = pd.concat([finaldata, data], sort=False, ignore_index=True)\n",
        "\n",
        "j=26\n",
        "\n",
        "#For dataset of digits\n",
        "for i in range(1,11,1):\n",
        "  datapath = \"/content/drive/My Drive/Smart Glove Data/digits with flex only/Digit\"+str(i)+\".csv\"\n",
        "  data = pd.read_csv(datapath)\n",
        "  for k in data.columns:     #data.columns[w:] if you have w column of line description \n",
        "    data[k] = data[k].fillna(data[k].median())\n",
        "  data = data.filter(['index','middle','ring','little','thumb'])\n",
        "  data.insert(5,'Character',j)\n",
        "  j=j+1\n",
        "  finaldata = pd.concat([finaldata, data], sort=False, ignore_index=True)\n",
        "\n",
        "j=0\n",
        "\n",
        "#For datasets having 5,000 values - Characters\n",
        "for i in ascii_uppercase:\n",
        "  datapath = \"/content/drive/My Drive/Smart Glove Data/alphabets with flex only/Alphabet2\"+i+\".csv\"\n",
        "  data = pd.read_csv(datapath)\n",
        "  for k in data.columns:     #data.columns[w:] if you have w column of line description \n",
        "    data[k] = data[k].fillna(data[k].median())\n",
        "  data = data.filter(['index','middle','ring','little','thumb'])\n",
        "  data.insert(5,'Character',j)\n",
        "  j=j+1\n",
        "  finaldata = pd.concat([finaldata, data], sort=False, ignore_index=True)\n",
        "\n",
        "j=0\n",
        "\n",
        "#For datasets having 10,000 values - Characters\n",
        "for i in ascii_uppercase:\n",
        "  datapath = \"/content/drive/My Drive/Smart Glove Data/alphabets with flex only/Alphabet3\"+i+\".csv\"\n",
        "  data = pd.read_csv(datapath)\n",
        "  for k in data.columns:     #data.columns[w:] if you have w column of line description \n",
        "    data[k] = data[k].fillna(data[k].median())\n",
        "  data = data.filter(['index','middle','ring','little','thumb'])\n",
        "  data.insert(5,'Character',j)\n",
        "  j=j+1\n",
        "  finaldata = pd.concat([finaldata, data], sort=False, ignore_index=True)\n",
        "\n",
        "j=26\n",
        "\n",
        "#For datasets having 5000 values - Digits\n",
        "for i in range(1,11,1):\n",
        "  datapath = \"/content/drive/My Drive/Smart Glove Data/digits with flex only/Digit\"+str(i)+\".csv\"\n",
        "  data = pd.read_csv(datapath)\n",
        "  for k in data.columns:     #data.columns[w:] if you have w column of line description \n",
        "    data[k] = data[k].fillna(data[k].median())\n",
        "  data = data.filter(['thumb','index','middle','ring','little'])\n",
        "  data.insert(5,'Character',j)\n",
        "  j=j+1\n",
        "  finaldata = pd.concat([finaldata, data], sort=False, ignore_index=True)\n",
        "\n",
        "j=26\n",
        "\n",
        "\n",
        "\n",
        "#For datasets having 10,000 values - Digits\n",
        "for i in range(1,11,1):\n",
        "  datapath = \"/content/drive/My Drive/Smart Glove Data/digits with flex only/Digit\"+str(i)+\".csv\"\n",
        "  data = pd.read_csv(datapath)\n",
        "  for k in data.columns:     #data.columns[w:] if you have w column of line description \n",
        "    data[k] = data[k].fillna(data[k].median())\n",
        "  data = data.filter(['thumb','index','middle','ring','little'])\n",
        "  data.insert(5,'Character',j)\n",
        "  j=j+1\n",
        "  finaldata = pd.concat([finaldata, data], sort=False, ignore_index=True)\n",
        "\n",
        "finaldata = finaldata[ (finaldata['thumb'].between(550, 750)) & (finaldata['index'].between(550, 750)) &\n",
        "                      (finaldata['middle'].between(550, 750)) & (finaldata['ring'].between(550, 750)) &\n",
        "                      (finaldata['little'].between(550, 750)) ]\n",
        "\n",
        "finaldata.isnull().any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index        False\n",
              "middle       False\n",
              "ring         False\n",
              "little       False\n",
              "thumb        False\n",
              "Character    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5RVdFV6SVpt",
        "colab_type": "code",
        "outputId": "0aa6cd1f-a934-4341-bc9b-5e6616bf6566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "finaldata"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>middle</th>\n",
              "      <th>ring</th>\n",
              "      <th>little</th>\n",
              "      <th>thumb</th>\n",
              "      <th>Character</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>612.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>687.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608.0</td>\n",
              "      <td>685.0</td>\n",
              "      <td>686.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>607.0</td>\n",
              "      <td>675.0</td>\n",
              "      <td>687.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>613.0</td>\n",
              "      <td>677.0</td>\n",
              "      <td>687.0</td>\n",
              "      <td>671.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>609.0</td>\n",
              "      <td>682.0</td>\n",
              "      <td>686.0</td>\n",
              "      <td>671.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446000</th>\n",
              "      <td>613.0</td>\n",
              "      <td>677.0</td>\n",
              "      <td>686.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446001</th>\n",
              "      <td>613.0</td>\n",
              "      <td>677.0</td>\n",
              "      <td>686.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446002</th>\n",
              "      <td>613.0</td>\n",
              "      <td>678.0</td>\n",
              "      <td>686.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446003</th>\n",
              "      <td>613.0</td>\n",
              "      <td>678.0</td>\n",
              "      <td>686.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446004</th>\n",
              "      <td>613.0</td>\n",
              "      <td>677.0</td>\n",
              "      <td>686.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>442332 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        index  middle   ring  little  thumb  Character\n",
              "0       612.0   679.0  687.0   672.0  673.0        0.0\n",
              "1       608.0   685.0  686.0   670.0  672.0        0.0\n",
              "2       607.0   675.0  687.0   670.0  673.0        0.0\n",
              "3       613.0   677.0  687.0   671.0  673.0        0.0\n",
              "4       609.0   682.0  686.0   671.0  673.0        0.0\n",
              "...       ...     ...    ...     ...    ...        ...\n",
              "446000  613.0   677.0  686.0   672.0  673.0       35.0\n",
              "446001  613.0   677.0  686.0   672.0  672.0       35.0\n",
              "446002  613.0   678.0  686.0   672.0  673.0       35.0\n",
              "446003  613.0   678.0  686.0   672.0  673.0       35.0\n",
              "446004  613.0   677.0  686.0   672.0  673.0       35.0\n",
              "\n",
              "[442332 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMvnyzpUHbWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_cols = ['thumb','index','middle','ring','little']\n",
        "X = finaldata[feature_cols] \n",
        "Y = finaldata.Character\n",
        "  \n",
        "\n",
        "# Splitting the dataset into train and test \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 100) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx_bKazn3JJy",
        "colab_type": "code",
        "outputId": "49b0be57-1ffa-4758-b02a-adedd80f4b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(\"Thumb: \",type(finaldata['thumb']))\n",
        "print(\"Index: \",type(finaldata['index']))\n",
        "print(\"Middle: \",type(finaldata['middle']))\n",
        "print(\"Ring: \",type(finaldata['ring']))\n",
        "print(\"Little: \",type(finaldata['little']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thumb:  <class 'pandas.core.series.Series'>\n",
            "Index:  <class 'pandas.core.series.Series'>\n",
            "Middle:  <class 'pandas.core.series.Series'>\n",
            "Ring:  <class 'pandas.core.series.Series'>\n",
            "Little:  <class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofshTWIdHxn3",
        "colab_type": "text"
      },
      "source": [
        "Training code. Decision tree classifier is used with default arguments (entropy criterion)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-AtMjzSHwG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAyx7IWCJMyr",
        "colab_type": "code",
        "outputId": "9004625e-571a-4e49-e925-c9905afd31e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([25., 12.,  6., ..., 31., 19., 32.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81btv52vICMs",
        "colab_type": "text"
      },
      "source": [
        "Accuracy Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23HqYVFtIDxu",
        "colab_type": "code",
        "outputId": "f026fff3-f14e-4bf0-d174-91fe5fcf2657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7929238884702337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_KMyBldZxLm",
        "colab_type": "text"
      },
      "source": [
        "# Testing using Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2DeCjc-Z7Sd",
        "colab_type": "code",
        "outputId": "68b44ba4-c60c-414e-d16d-6536119a4f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "#Linear Regression Testing\n",
        "regressor = LinearRegression()  \n",
        "regressor.fit(X_train, y_train) #training the algorithm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE45ebmdaK5u",
        "colab_type": "code",
        "outputId": "586a3bd5-7579-4151-f095-2e1d766fa786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-dd74dc8fb91e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt7TBzJ-bifW",
        "colab_type": "text"
      },
      "source": [
        "# **Testing using random forest classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRhmxM0fbpB5",
        "colab_type": "code",
        "outputId": "7578b693-beb8-40ec-9ca3-948090fbb845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "#Import Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTsgu6bubvJN",
        "colab_type": "code",
        "outputId": "591b2cf3-a63e-4f5e-eb83-b915ae7110f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8082592313489073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgkpXuQNLUKe",
        "colab_type": "text"
      },
      "source": [
        "Export model using pcikle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qk5274qLTEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle \n",
        "\n",
        "# save the model to disk\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))\n",
        " \n",
        "# some time later...\n",
        " \n",
        "# load the model from disk\n",
        "# loaded_model = pickle.load(open(filename, 'rb'))\n",
        "# result = loaded_model.score(X_test, Y_test)\n",
        "# print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvwCg0gixHSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimator = clf.estimators_[3]\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(estimator, out_file=\"tree.dot\", rounded=True, proportion=False, precision=2, filled=True)\n",
        "\n",
        "from subprocess import call\n",
        "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(filename = \"tree.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58ZJ_nGTeL9o",
        "colab_type": "text"
      },
      "source": [
        "# **Testing using KNN Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T6z7dW3eTWr",
        "colab_type": "code",
        "outputId": "82aede1f-c56a-4b6b-ef11-41a80ab2c9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCresjc1ekV0",
        "colab_type": "code",
        "outputId": "c141584f-30e2-422c-8fae-94e10e66d4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_pred = classifier.predict(X_train)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_train, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8386245607689128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "137xuWc2hJjA",
        "colab_type": "text"
      },
      "source": [
        "# **Testing using Support Vector Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo_Afs3VkiOG",
        "colab_type": "code",
        "outputId": "dd5886f7-7072-4e53-d083-df160d5e32da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "    \n",
        "# Initialise the Scaler \n",
        "scaler = StandardScaler() \n",
        "  \n",
        "# To scale data \n",
        "scaler.fit(finaldata) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aANkSN6Zuvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "X_train = preprocessing.scale(X_train)\n",
        "X_test = preprocessing.scale(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8ZFzkfAhQmw",
        "colab_type": "code",
        "outputId": "f4ca2b98-4771-4585-b3e8-61788b2066d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svclassifier = SVC(kernel='linear')\n",
        "svclassifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSQUfpE0hVHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = svclassifier.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr7lJuaXmSEl",
        "colab_type": "code",
        "outputId": "bf314f49-056b-4248-e54c-279fe3389d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "from sklearn.metrics import metrics\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e60fc025e0e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'metrics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EYMDsoNrltg",
        "colab_type": "text"
      },
      "source": [
        "# **Neural Net Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWLi2R3hrskG",
        "colab_type": "code",
        "outputId": "ac8a0c01-732f-4311-e36e-04ada8055ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "nnmodel = MLPClassifier()\n",
        "nnmodel.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGp1vqdRsK86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = nnmodel.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK0WdWoB8XHo",
        "colab_type": "code",
        "outputId": "5493d1b8-02b1-4de8-dc6e-e97ad31b77e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"Accuracy: \",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.36657121326299924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpUVbQ1WGc_m",
        "colab_type": "text"
      },
      "source": [
        "# IGNORE CODE FROM HERE ON OUT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQvBU5Bz4BUx",
        "colab_type": "code",
        "outputId": "2a328425-b26c-4ecd-81bc-11544389541d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "#IGNORE THIS.\n",
        "#Test window for importing files\n",
        "\n",
        "from string import ascii_uppercase\n",
        "for i in ascii_uppercase:\n",
        "  newi = str(i)\n",
        "  datapath = \"inputs/Alphabet\"+i+\".csv\"\n",
        "  print(datapath)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs/AlphabetA.csv\n",
            "inputs/AlphabetB.csv\n",
            "inputs/AlphabetC.csv\n",
            "inputs/AlphabetD.csv\n",
            "inputs/AlphabetE.csv\n",
            "inputs/AlphabetF.csv\n",
            "inputs/AlphabetG.csv\n",
            "inputs/AlphabetH.csv\n",
            "inputs/AlphabetI.csv\n",
            "inputs/AlphabetJ.csv\n",
            "inputs/AlphabetK.csv\n",
            "inputs/AlphabetL.csv\n",
            "inputs/AlphabetM.csv\n",
            "inputs/AlphabetN.csv\n",
            "inputs/AlphabetO.csv\n",
            "inputs/AlphabetP.csv\n",
            "inputs/AlphabetQ.csv\n",
            "inputs/AlphabetR.csv\n",
            "inputs/AlphabetS.csv\n",
            "inputs/AlphabetT.csv\n",
            "inputs/AlphabetU.csv\n",
            "inputs/AlphabetV.csv\n",
            "inputs/AlphabetW.csv\n",
            "inputs/AlphabetX.csv\n",
            "inputs/AlphabetY.csv\n",
            "inputs/AlphabetZ.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXYJ1kdcRT1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataset already imported in previous block. Ignore.\n",
        "# Function importing Dataset \n",
        "def importdata(): \n",
        "    balance_data = pd.read_csv( \n",
        "'https://archive.ics.uci.edu/ml/machine-learning-'+\n",
        "'databases/balance-scale/balance-scale.data', \n",
        "    sep= ',', header = None) \n",
        "      \n",
        "    # Printing the dataswet shape \n",
        "    print (\"Dataset Length: \", len(balance_data)) \n",
        "    print (\"Dataset Shape: \", balance_data.shape) \n",
        "      \n",
        "    # Printing the dataset obseravtions \n",
        "    print (\"Dataset: \",balance_data.head()) \n",
        "    return balance_data "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYR_hbixTmRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to split the dataset \n",
        "def splitdataset(balance_data): \n",
        "  \n",
        "    # Separating the target variable \n",
        "    X = balance_data.values['thumb','index','middle','ring','little'] \n",
        "    Y = balance_data.values['Character'] \n",
        "  \n",
        "    # Splitting the dataset into train and test \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 100) \n",
        "      \n",
        "    return X, Y, X_train, X_test, y_train, y_test "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soCmYd0pTrI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to perform training with giniIndex. \n",
        "def train_using_gini(X_train, X_test, y_train): \n",
        "  \n",
        "    # Creating the classifier object \n",
        "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,max_depth=3, min_samples_leaf=5) \n",
        "  \n",
        "    # Performing training \n",
        "    clf_gini.fit(X_train, y_train) \n",
        "    return clf_gini "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ueu6abITxgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to perform training with entropy. \n",
        "def train_using_entropy(X_train, X_test, y_train): \n",
        "  \n",
        "    # Decision tree with entropy \n",
        "    clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, max_depth = 3, min_samples_leaf = 5) \n",
        "  \n",
        "    # Performing training \n",
        "    clf_entropy.fit(X_train, y_train) \n",
        "    return clf_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1op8SkKUAuw",
        "colab_type": "code",
        "outputId": "3ddf886a-7ac0-46a7-998d-baf0012c8f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Function to make predictions \n",
        "def prediction(X_test, clf_object): \n",
        "  \n",
        "    # Predicton on test with giniIndex \n",
        "    y_pred = clf_object.predict(X_test) \n",
        "    print(\"Predicted values:\") \n",
        "    print(y_pred) \n",
        "    return y_pred \n",
        "      \n",
        "# Function to calculate accuracy \n",
        "#def cal_accuracy(y_test, y_pred): \n",
        "      \n",
        "print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred)) \n",
        "      \n",
        "print (\"Accuracy : \", accuracy_score(y_test,y_pred)*100) \n",
        "      \n",
        "print(\"Report : \", classification_report(y_test, y_pred)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:  [[3879  424    0    0    1    0    0    0    0    0    0    0    0   30\n",
            "    67    1   51   77    0   26    0    4   30    5   52  112   61]\n",
            " [ 550 3704    2    0    0    0    0    0    0    0    0    0    0   26\n",
            "    64    0   48  215    0   10    0    1  114    0    0   10   76]\n",
            " [   0    0 4641   30    1    0    1    0    1    0    0    0    0    0\n",
            "     0   14   33  103    1    5    2    0    0    0    0    0    0]\n",
            " [   0    0   24 4776    3    0    0    0    0    0    0    0    0    0\n",
            "     0    1    2    2    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0   13    3 3330   31  175   19  556    0    0    0    0    8\n",
            "     5   58   76    2  301   75    8  206    1    0    2    1    1]\n",
            " [   0    0    0    0   18 4677    0    1   79    0    0    0    0    0\n",
            "     0    0    0    0   46    1    0    3    0    0    0    0    0]\n",
            " [   0    0    0    0  140    0 4498   29    5    0    0    0    0    1\n",
            "     0    5    7    0    9    0    0   21    0    0    0    0    0]\n",
            " [   0    0    0    0    5    0   23 4733    4    0    3    0    0    0\n",
            "     0   34    5    0    8    0    0   17    0    0    0    0    0]\n",
            " [   0    0   10    2  647  202   43   27 2483   77    2   60  174  253\n",
            "    43   59   39    0  602   57    8   44    0    3    2    0    0]\n",
            " [   0    0    0    0    0    0    0    0   56 3560   83  109    0  485\n",
            "   182   78    0    0    4  237    1    0    0    7    0    0    0]\n",
            " [   0    0    0    0    0    0    0    3    0   79 3954   10    0   28\n",
            "   415   83    1    0   51    4   94    0    0   13    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0   74  148    9 3655  146  128\n",
            "   161  156    0    0   71   60    1    0    0   55    9    0    0]\n",
            " [   0    0    0    0    0    0    0    0  202    0    0  204 3980  368\n",
            "    82   19    0    0   64    0    0    0    0   16    6    0    0]\n",
            " [  42   32    1    0   17    6    2    2  316  629   44  148  376 2534\n",
            "   168   63   10   61   91  189    0    1   19   21    2    3    2]\n",
            " [ 114   78    0    0    0    2    0    0   54  262  535  196   95  158\n",
            "  1983   59   49  118  124   67    5    6   26   14   16   20    5]\n",
            " [   0    1   38   16   76    3   10   64   55   72   99  186    4   68\n",
            "    90 3585  143   13   46   32   32   65   10    6    6    0   11]\n",
            " [  80   34   44   19   76    0   45   21   27    0    0    0    0   17\n",
            "    49  199 3220  566   36   56   22   77  175   16    1   10   17]\n",
            " [  87  275  106   17    3    0    0    0    0    0    0    0    0   67\n",
            "    86   26  523 3137    1  157    3   26  187    8    0   22   29]\n",
            " [   0    0    1    0  471   98   48   29  625    1   60   79   49   80\n",
            "   120   75   58    0 2852   70    2   42    0    8    3    0    0]\n",
            " [  41    6   43    4  110    9    8    1  104  283    5   77    1  211\n",
            "   121   69  102  263  124 3185    3    9   45    6    0    8   26]\n",
            " [   0    0    0    0    5    0    1    8    8    0   81    1    0    1\n",
            "    12   54   25    0    4    3 4369  149    2   20    2    1   19]\n",
            " [   1    2    2    5  282    1   55   27   38    0    0    0    0    4\n",
            "     0   85   65   25   54    5  300 3274  508    4    2    4   14]\n",
            " [  47  127    0    0    6    0    0    0    0    0    0    0    0   24\n",
            "    35   13  151  283    0   47    9  399 3584   40    0   32   34]\n",
            " [  16    0    0    0    0    0    0    0    1    3   32   58    7   11\n",
            "     9    3   16   33    2    2   18    1   10 4542   46    2    0]\n",
            " [  12    0    0    0    3    0    1    0    0    0    0    9    0    3\n",
            "     4    5    1    0    1    0    0    1    0   33 4374   34    0]\n",
            " [  26    4    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     3    1    1    4    0    0    0    0    3    1   24 4738    0]\n",
            " [  40   35    0    0    1    0    0    0    0    0    0    0    0    2\n",
            "     1    6   10    9    0    7    8    5    4    0    0    0 2912]]\n",
            "Accuracy :  79.05209155485399\n",
            "Report :                precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.80      0.80      4820\n",
            "         1.0       0.78      0.77      0.78      4820\n",
            "         2.0       0.94      0.96      0.95      4832\n",
            "         3.0       0.98      0.99      0.99      4808\n",
            "         4.0       0.64      0.68      0.66      4871\n",
            "         5.0       0.93      0.97      0.95      4825\n",
            "         6.0       0.92      0.95      0.93      4715\n",
            "         7.0       0.95      0.98      0.97      4832\n",
            "         8.0       0.53      0.51      0.52      4837\n",
            "         9.0       0.70      0.74      0.72      4802\n",
            "        10.0       0.81      0.84      0.82      4735\n",
            "        11.0       0.76      0.78      0.77      4673\n",
            "        12.0       0.82      0.81      0.81      4941\n",
            "        13.0       0.56      0.53      0.55      4779\n",
            "        14.0       0.54      0.50      0.52      3986\n",
            "        15.0       0.75      0.76      0.76      4731\n",
            "        16.0       0.69      0.67      0.68      4807\n",
            "        17.0       0.64      0.66      0.65      4760\n",
            "        18.0       0.63      0.60      0.62      4771\n",
            "        19.0       0.74      0.65      0.70      4864\n",
            "        20.0       0.89      0.92      0.91      4765\n",
            "        21.0       0.75      0.69      0.72      4757\n",
            "        22.0       0.76      0.74      0.75      4831\n",
            "        23.0       0.94      0.94      0.94      4812\n",
            "        24.0       0.96      0.98      0.97      4481\n",
            "        25.0       0.95      0.99      0.97      4805\n",
            "        26.0       0.91      0.96      0.93      3040\n",
            "\n",
            "    accuracy                           0.79    126700\n",
            "   macro avg       0.79      0.79      0.79    126700\n",
            "weighted avg       0.79      0.79      0.79    126700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh7j-wPLT4_-",
        "colab_type": "code",
        "outputId": "d3480456-c4c5-4510-97e6-20b5e2956d71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "# Driver code \n",
        "def main(): \n",
        "      \n",
        "    # Building Phase \n",
        "    data = importdata() \n",
        "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data) \n",
        "    clf_gini = train_using_gini(X_train, X_test, y_train) \n",
        "    clf_entropy = train_using_entropy(X_train, X_test, y_train) \n",
        "      \n",
        "    # Operational Phase \n",
        "    print(\"Results Using Gini Index:\") \n",
        "      \n",
        "    # Prediction using gini \n",
        "    y_pred_gini = prediction(X_test, clf_gini) \n",
        "    cal_accuracy(y_test, y_pred_gini) \n",
        "      \n",
        "    print(\"Results Using Entropy:\") \n",
        "    # Prediction using entropy \n",
        "    y_pred_entropy = prediction(X_test, clf_entropy) \n",
        "    cal_accuracy(y_test, y_pred_entropy) \n",
        "      \n",
        "      \n",
        "if __name__==\"__main__\": \n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-2537cf2a47fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-2537cf2a47fb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Building Phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mclf_gini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_using_gini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'importdata' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBosUSmT-SPP",
        "colab_type": "text"
      },
      "source": [
        "# **Tensorflow Part - Please ignore to avoid depression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1pLU6vaeCbq",
        "colab_type": "code",
        "outputId": "99370a9a-1a74-4d90-fe59-beb65b243c6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "#from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td-RucqAX8iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_features = X_train.shape[1]\n",
        "\n",
        "n_neurons1 = 35\n",
        "n_neurons2 = 18\n",
        "n_neurons3 = 9\n",
        "\n",
        "net = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0S0EFjIZHYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(dtype = tf.float32, shape=[None, n_features])\n",
        "Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKZJ0Cz2dFku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sigma = 1\n",
        "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
        "bias_initializer = tf.zeros_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGZV8Xb-ZaPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_1 = tf.Variable(weight_initializer([n_features, n_neurons1]))\n",
        "bias_hidden1 = tf.Variable(bias_initializer([n_neurons1]))\n",
        "\n",
        "hidden_2 = tf.Variable(weight_initializer([n_neurons1, n_neurons2]))\n",
        "bias_hidden2 = tf.Variable(bias_initializer([n_neurons2]))\n",
        "\n",
        "hidden_3 = tf.Variable(weight_initializer([n_neurons2, n_neurons3]))\n",
        "bias_hidden3 = tf.Variable(bias_initializer([n_neurons3]))\n",
        "\n",
        "out_ = tf.Variable(weight_initializer([n_neurons3, 1]))\n",
        "bias = tf.Variable(bias_initializer([1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqzLFLRXaQ_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden1 = tf.nn.relu(tf.add(tf.matmul(X, hidden_1), bias_hidden1))\n",
        "hidden2 = tf.nn.relu(tf.add(tf.matmul(hidden1, hidden_2), bias_hidden2))\n",
        "hidden3 = tf.nn.relu(tf.add(tf.matmul(hidden2, hidden_3), bias_hidden3))\n",
        "\n",
        "out = tf.transpose(tf.add(tf.matmul(hidden3, out_), bias))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLEJgD15Z4WS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cost function\n",
        "mse = tf.reduce_mean(tf.squared_difference(out, Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8FhORmaebUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer\n",
        "opt = tf.train.AdamOptimizer().minimize(mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxU2ytZFebvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run initializer\n",
        "net.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwbKHIMHbQ_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training model\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "for e in range(epochs):\n",
        "  shuffle_data = np.random.permutation(np.arange(len(y_train)))\n",
        "  #X_train = X_train[shuffle_data]\n",
        "  #y_train = y_train[shuffle_data]\n",
        "\n",
        "  for i in range(0, len(y_train) // batch_size):\n",
        "    start = i*batch_size\n",
        "    batch_x = X_train[start:start + batch_size]\n",
        "    batch_y = y_train[start:start + batch_size]\n",
        "    #Optimizer\n",
        "    net.run(opt, feed_dict={X: batch_x, Y: batch_y})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6byOoIxAeGof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = net.run(out, feed_dict={X: X_test})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3bQO8FqhSMH",
        "colab_type": "code",
        "outputId": "4f369f46-4b21-448a-cc98-aab535722561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "#print(y_test)\n",
        "y_test1 = y_test.to_numpy()\n",
        "print(y_test1)\n",
        "print(y_test1.shape)\n",
        "print(type(y_test1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[25.  8.  6. ... 31. 19. 32.]\n",
            "(132700,)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC3LvUoAheYh",
        "colab_type": "code",
        "outputId": "a5c8c23f-cbb8-47c5-f731-14b091234deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(pred)\n",
        "print(type(pred))\n",
        "pred1 = pred.flatten()\n",
        "print(pred1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[13.445344 14.058702 13.446109 ... 13.488316 13.558735 13.427417]]\n",
            "<class 'numpy.ndarray'>\n",
            "[13.445344 14.058702 13.446109 ... 13.488316 13.558735 13.427417]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4s1TpQWe4nt",
        "colab_type": "code",
        "outputId": "8cbac1b2-b589-4304-b943-ad5a0243717b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "accuracy_score = r2_score(y_test1, pred1)\n",
        "print(accuracy_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0028474498022770245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qeIDAOLzYbv",
        "colab_type": "text"
      },
      "source": [
        "# **DNN Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vG1u_7XfHgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputFunction = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=100,num_epochs=1000,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy-liuQIzu1B",
        "colab_type": "code",
        "outputId": "989c62d0-7d1f-4c3e-bc97-7678aa773c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        }
      },
      "source": [
        "from tensorflow.estimator import DNNClassifier\n",
        "dnnClassifierModel = DNNClassifier(hidden_units=[512, 256, 128], feature_columns=feature_cols, n_classes=2, activation_fn=tf.nn.tanh,optimizer=lambda: tf.train.AdamOptimizer(                                                learning_rate=tf.train.exponential_decay(learning_rate=0.001,                                                  global_step=tf.train.get_global_step(),decay_steps=1000,decay_rate=0.96)))\n",
        "dnnClassifierModel.train(input_fn=inputFunction,steps=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp4vekxxe0\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp4vekxxe0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21dcac51d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-ec436852151a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDNNClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdnnClassifierModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m                                                \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexponential_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m                                                  \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdnnClassifierModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputFunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1159\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1191\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1192\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    809\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m           batch_norm=batch_norm)\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     super(DNNClassifier, self).__init__(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[0;34m(features, labels, mode, head, hidden_units, feature_columns, optimizer, activation_fn, dropout, input_layer_partitioner, config, use_tpu, batch_norm)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         batch_norm=batch_norm)\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     return _get_dnn_estimator_spec(use_tpu, head, features, labels, mode,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[0;34m(features, mode)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mbatch_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         name='dnn')\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdnn_logit_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in converted code:\n    relative to /usr/local/lib/python3.6/dist-packages:\n\n    tensorflow_estimator/python/estimator/canned/dnn.py:252 call  *\n        net = self._input_layer(features)\n    tensorflow_core/python/feature_column/feature_column.py:338 __call__\n        from_template=True)\n    tensorflow_core/python/ops/template.py:393 __call__\n        return self._call_func(args, kwargs)\n    tensorflow_core/python/ops/template.py:355 _call_func\n        result = self._func(*args, **kwargs)\n    tensorflow_core/python/feature_column/feature_column.py:182 _internal_input_layer\n        feature_columns = _normalize_feature_columns(feature_columns)\n    tensorflow_core/python/feature_column/feature_column.py:2300 _normalize_feature_columns\n        'Given (type {}): {}.'.format(type(column), column))\n\n    ValueError: Items of feature_columns must be a _FeatureColumn. Given (type <class 'str'>): thumb.\n    \n    originally defined at:\n      File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 108, in dnn_logit_fn\n        name='dnn')\n      File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 191, in __init__\n        create_scope_now=False)\n      File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py\", line 328, in __init__\n        self._name, _internal_input_layer, create_scope_now_=create_scope_now)\n      File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/template.py\", line 161, in make_template\n        **kwargs)\n    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bJ-JI1S0k6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}